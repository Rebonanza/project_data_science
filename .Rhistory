accessSecret <- "SSHmflyTIbIqN6Zrl3xFETNNj9D2hyudf7DVdrmZWFzlv"
token = create_token(
app = "sentimentAnalysisBooster",
consumer_key = api_key,
consumer_secret = api_secret_key,
access_token = accessToken,
access_secret = accessSecret,
set_renv = TRUE
)
auth_save(token, "tweetAccess")
auth_as("tweetAccess")
auth_sitrep()
auth_as("tweetAccess")
dataTweets <- search_tweets('#MiSTerFPGA')
## store api keys (these are fake example values; replace with your own keys)
api_key <- "FBox1hjtTDLO3VZvyKWIZx77j"
api_secret_key <- "b3oOc7sGKHrzCdlHjFP8L6U5zWOdhSiEv3g3TJAfwQ02EV6IW5"
bearer_token <- "AAAAAAAAAAAAAAAAAAAAAF4YjgEAAAAADwzHHipo40WWiP%2F7NYjSaRvL5Gk%3DmLyBXX31ggRKxdEYkNmIid8uEKkzKiQ951aO1lJgE1qvzBC3JS"
clientId <- "MVoyLWVTMEVrWTd6OFUzTGxqbVI6MTpjaQ"
clientSecret <- "URnCd6sUHe4nieKbfnQ1xRJUwmhNOnfCLvXN7RioBY9w07_nPa"
accessToken <- "1592089064374534145-6hpvtXEwCUBMK7wbZCIXaRXTlarEWc"
accessSecret <- "h35r7DP0dR4AcUwBQqUXE5diaPTDkY7TEm4s41cT9X3xp"
token = create_token(
app = "sentimentAnalysisBooster",
consumer_key = api_key,
consumer_secret = api_secret_key,
access_token = accessToken,
access_secret = accessSecret,
set_renv = TRUE
)
auth_save(token, "tweetAccess")
auth_as("tweetAccess")
auth_sitrep()
dataTweets <- search_tweets('#onepiece')
get_trends(
woeid = 1,
lat = NULL,
lng = NULL,
exclude_hashtags = FALSE,
token = NULL,
parse = TRUE
)
get_trends(
woeid = 1,
lat = NULL,
lng = NULL,
exclude_hashtags = FALSE,
token = NULL,
parse = TRUE
)
## store api keys (these are fake example values; replace with your own keys)
api_key <- "FBox1hjtTDLO3VZvyKWIZx77j"
api_secret_key <- "b3oOc7sGKHrzCdlHjFP8L6U5zWOdhSiEv3g3TJAfwQ02EV6IW5"
bearer_token <- "AAAAAAAAAAAAAAAAAAAAAF4YjgEAAAAADwzHHipo40WWiP%2F7NYjSaRvL5Gk%3DmLyBXX31ggRKxdEYkNmIid8uEKkzKiQ951aO1lJgE1qvzBC3JS"
clientId <- "MVoyLWVTMEVrWTd6OFUzTGxqbVI6MTpjaQ"
clientSecret <- "URnCd6sUHe4nieKbfnQ1xRJUwmhNOnfCLvXN7RioBY9w07_nPa"
accessToken <- "1592089064374534145-6hpvtXEwCUBMK7wbZCIXaRXTlarEWc"
accessSecret <- "h35r7DP0dR4AcUwBQqUXE5diaPTDkY7TEm4s41cT9X3xp"
token = create_token(
app = "sentimentAnalysisBooster",
consumer_key = api_key,
consumer_secret = api_secret_key,
access_token = accessToken,
access_secret = accessSecret,
set_renv = TRUE
)
auth_save(token, "tweetAccess")
auth_as("tweetAccess")
auth_sitrep()
dataTweets <- search_tweets('#onepiece')
#dataTweets <- sapply(dataTweet, function(x) x$getText())
View(dataTweets)
dataVaksin <- search_tweets('#vaksincovid19', n=500, include_rts=FALSE)
dataBooster <- search_tweets('#vaksinbooster', n=500, include_rts=FALSE)
data
#dataTweets <- sapply(dataTweet, function(x) x$getText())
dataVaksin <- search_tweets('#vaksincovid19', n=500, include_rts=FALSE)
dataBooster <- search_tweets('#vaksinbooster', n=500, include_rts=FALSE)
#dataTweets <- sapply(dataTweet, function(x) x$getText())
dataVaksinCovid <- search_tweets('#vaksincovid19', n=500, include_rts=FALSE)
dataBooster <- search_tweets('#vaksinbooster', n=500, include_rts=FALSE)
dataVaksin <- search_tweets('#vaksin', n=500, include_rts=FALSE)
#dataTweets <- sapply(dataTweet, function(x) x$getText())
dataVaksinCovid <- search_tweets('#vaksincovid19', n=500, include_rts=FALSE)
dataVaksinBooster <- search_tweets('#vaksinbooster', n=500, include_rts=FALSE)
dataVaksin <- search_tweets('#vaksin', n=500, include_rts=FALSE)
dataBooster <- search_tweets('#booster', n=500, include_rts=FALSE)
#dataTweets <- sapply(dataTweet, function(x) x$getText())
View(dataBooster)
dataVaksinCovid <- search_tweets('#vaksincovid19', n=500, include_rts=FALSE)
dataVaksinBooster <- search_tweets('#vaksinbooster', n=500, include_rts=FALSE)
dataVaksin <- search_tweets('#vaksin', n=500, include_rts=FALSE)
dataBooster <- search_tweets('#booster', n=500, include_rts=FALSE)
data <- merge(dataVaksinCovid, dataVaksin)
#dataTweets <- sapply(dataTweet, function(x) x$getText())
View(data)
dataVaksinCovid <- search_tweets('#vaksincovid19', n=500, include_rts=FALSE)
data <- rbind(dataVaksinCovid, dataVaksin)
View(data)
data <- rbind(dataVaksinCovid, dataVaksin, dataVaksinBooster, dataBooster)
View(data)
data <- rbind(dataVaksinCovid, dataVaksin, dataVaksinBooster, dataBooster)
data <- data %>% select(screen_name, Fulltext)
data <- rbind(dataVaksinCovid, dataVaksin, dataVaksinBooster, dataBooster)
data <- data %>% select(Fulltext)
View(data)
data <- rbind(dataVaksinCovid, dataVaksin, dataVaksinBooster, dataBooster)
data <- data %>% select(full_text)
View(data)
dataClean <- gsub("(RT|via)((?:\\b\\w*@\\w+)+)", "",data)
dataClean = gsub("@\\w+","",dataClean)
dataClean = gsub("[[:punct:]]", "", dataClean)
dataClean = gsub("[[:digit:]]", "", dataClean)
dataClean = gsub("http\\w+","",dataClean)
dataClean = gsub("[ \t]{2,}","",dataClean)
dataClean = gsub("^\\s+|\\s+$","",dataClean)
dataClean = gsub("note","",dataClean)
try.error = function(x)
{
y = NA
try.error = tryCatch(tolower(X), error=function(e) e)
if(!inherits(try.error, "error"))
y= tolower(x)
return(y)
}
dataTweetsClean = sapply(dataTweetsClean, try.error)
dataClean <- gsub("(RT|via)((?:\\b\\w*@\\w+)+)", "",data)
dataClean = gsub("@\\w+","",dataClean)
dataClean = gsub("[[:punct:]]", "", dataClean)
dataClean = gsub("[[:digit:]]", "", dataClean)
dataClean = gsub("http\\w+","",dataClean)
dataClean = gsub("[ \t]{2,}","",dataClean)
dataClean = gsub("^\\s+|\\s+$","",dataClean)
dataClean = gsub("note","",dataClean)
try.error = function(x)
{
y = NA
try.error = tryCatch(tolower(X), error=function(e) e)
if(!inherits(try.error, "error"))
y= tolower(x)
return(y)
}
dataClean = sapply(dataClean, try.error)
dataClean = dataClean[i!is.na(dataClean)]
dataClean <- gsub("(RT|via)((?:\\b\\w*@\\w+)+)", "",data)
dataClean = gsub("@\\w+","",dataClean)
dataClean = gsub("[[:punct:]]", "", dataClean)
dataClean = gsub("[[:digit:]]", "", dataClean)
dataClean = gsub("http\\w+","",dataClean)
dataClean = gsub("[ \t]{2,}","",dataClean)
dataClean = gsub("^\\s+|\\s+$","",dataClean)
dataClean = gsub("note","",dataClean)
try.error = function(x)
{
y = NA
try.error = tryCatch(tolower(X), error=function(e) e)
if(!inherits(try.error, "error"))
y= tolower(x)
return(y)
}
dataClean = sapply(dataClean, try.error)
dataClean = dataClean[!is.na(dataClean)]
names(dataClean) = NULL
View(data)
View(data)
dataClean <- gsub("(RT|via)((?:\\b\\w*@\\w+)+)", "",data)
dataClean = gsub("@\\w+","",dataClean)
dataClean = gsub("[[:punct:]]", "", dataClean)
dataClean = gsub("[[:digit:]]", "", dataClean)
dataClean = gsub("http\\w+","",dataClean)
dataClean = gsub("[ \t]{2,}","",dataClean)
dataClean = gsub("^\\s+|\\s+$","",dataClean)
dataClean = gsub("note","",dataClean)
dataClean <- dataClean %>%
select(full_text) %>%
unnest_tokens(word, full_text)
dataClean <- gsub("(RT|via)((?:\\b\\w*@\\w+)+)", "",data)
dataClean = gsub("@\\w+","",dataClean)
dataClean = gsub("[[:punct:]]", "", dataClean)
dataClean = gsub("[[:digit:]]", "", dataClean)
dataClean = gsub("http\\w+","",dataClean)
dataClean = gsub("[ \t]{2,}","",dataClean)
dataClean = gsub("^\\s+|\\s+$","",dataClean)
dataClean = gsub("note","",dataClean)
tweet.Kata_stem <- tweet.Kata %>%
select(stripped_text1) %>%
unnest_tokens(word, stripped_text1)
dataClean <- gsub("(RT|via)((?:\\b\\w*@\\w+)+)", "",data)
dataClean = gsub("@\\w+","",dataClean)
dataClean = gsub("[[:punct:]]", "", dataClean)
dataClean = gsub("[[:digit:]]", "", dataClean)
dataClean = gsub("http\\w+","",dataClean)
dataClean = gsub("[ \t]{2,}","",dataClean)
dataClean = gsub("^\\s+|\\s+$","",dataClean)
dataClean = gsub("note","",dataClean)
try.error = function(x)
{
y = NA
try.error = tryCatch(tolower(X), error=function(e) e)
if(!inherits(try.error, "error"))
y= tolower(x)
return(y)
}
dataClean = sapply(dataClean, try.error)
dataClean = dataClean[!is.na(dataClean)]
names(dataClean) = NULL
dataClean <- gsub("(RT|via)((?:\\b\\w*@\\w+)+)", "",data)
dataClean = gsub("@\\w+","",dataClean)
dataClean = gsub("[[:punct:]]", "", dataClean)
dataClean = gsub("[[:digit:]]", "", dataClean)
dataClean = gsub("http\\w+","",dataClean)
dataClean = gsub("[ \t]{2,}","",dataClean)
dataClean = gsub("^\\s+|\\s+$","",dataClean)
dataClean = gsub("note","",dataClean)
try.error = function(x)
{
y = NA
try.error = tryCatch(tolower(X), error=function(e) e)
if(!inherits(try.error, "error"))
y= tolower(x)
return(y)
}
dataClean = sapply(dataClean, try.error)
dataClean = dataClean[!is.na(dataClean)]
names(dataClean) = NULL
dataClean
dataClean <- gsub("(RT|via)((?:\\b\\w*@\\w+)+)", "",data)
dataClean = gsub("@\\w+","",dataClean)
dataClean = gsub("[[:punct:]]", "", dataClean)
dataClean = gsub("[[:digit:]]", "", dataClean)
dataClean = gsub("http\\w+","",dataClean)
dataClean = gsub("[ \t]{2,}","",dataClean)
dataClean = gsub("^\\s+|\\s+$","",dataClean)
dataClean = gsub("note","",dataClean)
try.error = function(x)
{
y = NA
try.error = tryCatch(tolower(X), error=function(e) e)
if(!inherits(try.error, "error"))
y= tolower(x)
return(y)
}
dataClean = sapply(dataClean, try.error)
dataClean = dataClean[!is.na(dataClean)]
#names(dataClean) = NULL
dataClean
dataClean <- gsub("(RT|via)((?:\\b\\w*@\\w+)+)", "",data)
dataClean = gsub("@\\w+","",dataClean)
dataClean = gsub("[[:punct:]]", "", dataClean)
dataClean = gsub("[[:digit:]]", "", dataClean)
dataClean = gsub("http\\w+","",dataClean)
dataClean = gsub("[ \t]{2,}","",dataClean)
dataClean = gsub("^\\s+|\\s+$","",dataClean)
dataClean = gsub("note","",dataClean)
try.error = function(x)
{
y = NA
try.error = tryCatch(tolower(X), error=function(e) e)
if(!inherits(try.error, "error"))
y= tolower(x)
return(y)
}
#dataClean = sapply(dataClean, try.error)
#dataClean = dataClean[!is.na(dataClean)]
#names(dataClean) = NULL
dataClean
tweet.Kata$stripped_text1 <- gsub("http\\S+","",data$full_text)
data$stripped_text1 <- gsub("http\\S+","",data$full_text)
View(data)
knitr::opts_chunk$set(echo = TRUE)
data$stripped_text1 <- gsub("http\\S+","",data$full_text)
data <- data %>%
select(stripped_text1) %>%
unnest_tokens(word, stripped_text1)
data$stripped_text1 <- gsub("http\\S+","",data$full_text)
data <- data %>%
select(stripped_text1) %>% unnest_tokens(word, stripped_text1)
library(openssl)
library(httpuv)
library(rtweet)
library(SnowballC)
library(httr)
#library(twitteR)
#library(Rstem)
library(textdata)
library(purrr)
library(tm)
library(NLP)
library(SentimentAnalysis)
library(RColorBrewer)
library(wordcloud)
#library(sentiment)
#library(foo)
library(tidyverse)
library(tidytext)
library(e1071)
library(gmodels)
library(plyr)
library(plotly)
library(DT)
library(sass)
## store api keys (these are fake example values; replace with your own keys)
api_key <- "FBox1hjtTDLO3VZvyKWIZx77j"
api_secret_key <- "b3oOc7sGKHrzCdlHjFP8L6U5zWOdhSiEv3g3TJAfwQ02EV6IW5"
bearer_token <- "AAAAAAAAAAAAAAAAAAAAAF4YjgEAAAAADwzHHipo40WWiP%2F7NYjSaRvL5Gk%3DmLyBXX31ggRKxdEYkNmIid8uEKkzKiQ951aO1lJgE1qvzBC3JS"
clientId <- "MVoyLWVTMEVrWTd6OFUzTGxqbVI6MTpjaQ"
clientSecret <- "URnCd6sUHe4nieKbfnQ1xRJUwmhNOnfCLvXN7RioBY9w07_nPa"
accessToken <- "1592089064374534145-6hpvtXEwCUBMK7wbZCIXaRXTlarEWc"
accessSecret <- "h35r7DP0dR4AcUwBQqUXE5diaPTDkY7TEm4s41cT9X3xp"
token = create_token(
app = "sentimentAnalysisBooster",
consumer_key = api_key,
consumer_secret = api_secret_key,
access_token = accessToken,
access_secret = accessSecret,
set_renv = TRUE
)
auth_save(token, "tweetAccess")
auth_as("tweetAccess")
auth_sitrep()
dataVaksinCovid <- search_tweets('#vaksincovid19', n=500, include_rts=FALSE)
dataVaksinCovid <- search_tweets('#vaksincovid19', n=500, include_rts=FALSE)
dataVaksinBooster <- search_tweets('#vaksinbooster', n=500, include_rts=FALSE)
dataVaksin <- search_tweets('#vaksin', n=500, include_rts=FALSE)
dataBooster <- search_tweets('#booster', n=500, include_rts=FALSE)
#dataTweets <- sapply(dataTweet, function(x) x$getText())
data <- rbind(dataVaksinCovid, dataVaksin, dataVaksinBooster, dataBooster)
data <- data %>% select(full_text)
data$stripped_text1 <- gsub("http\\S+","",data$full_text)
data <- data %>%
select(stripped_text1) %>%
unnest_tokens(word, stripped_text1)
View(data)
View(data)
data$stripped_text1 <- gsub("http\\S+","",data$full_text)
cleanedData <- data %>%
anti_join(stop_words)
View(cleanedData)
class_emotion = classify_emotion(cleanedData, algorithm="bayes", prior=1.0)
library(openssl)
library(httpuv)
library(rtweet)
library(SnowballC)
library(httr)
#library(twitteR)
#library(Rstem)
library(textdata)
library(purrr)
library(tm)
library(NLP)
library(SentimentAnalysis)
library(RColorBrewer)
library(wordcloud)
library(sentiment)
library(openssl)
library(httpuv)
library(rtweet)
library(SnowballC)
library(httr)
#library(twitteR)
#library(Rstem)
library(textdata)
library(purrr)
library(tm)
library(NLP)
library(SentimentAnalysis)
library(RColorBrewer)
library(wordcloud)
library(sentiment)
install.packages("sentiment")
install.packages("caret")
library(openssl)
library(httpuv)
library(rtweet)
library(SnowballC)
library(httr)
#library(twitteR)
#library(Rstem)
library(textdata)
library(purrr)
library(tm)
library(NLP)
library(SentimentAnalysis)
library(RColorBrewer)
library(wordcloud)
#library(sentiment)
#library(foo)
library(tidyverse)
library(tidytext)
library(e1071)
library(caret)
library(syuzhet)
library(gmodels)
library(plyr)
library(plotly)
library(DT)
library(sass)
# Menjadikan semua text menjadi lowercase atau huruf kecil
data1 = data
data <- tolower(data)
# replace blank space ("RT")
data <- gsub("rt", "", data)
# replace twitter @ username handle
data <- gsub("@\\w+", "", data)
# Menghilangkan tanda baca
data <- gsub("[[:punct:]]", "", data)
# Menghilangkan link
data <- gsub("http\\w+", "", data)
# Menghilangkan Tabs
data <- gsub("[ |\t]{2,}", "", data)
# Menghapus lahan kosong di awal tweet
data <- gsub("^ ", "", data)
# Menghapus lahan kosong di akhir tweet
data <- gsub(" $", "", data)
dataClean <- tm_map(dataClean, removeun)
knitr::opts_chunk$set(echo = TRUE)
library(openssl)
library(httpuv)
library(rtweet)
library(SnowballC)
library(httr)
#library(twitteR)
#library(Rstem)
library(textdata)
library(purrr)
library(tm)
library(NLP)
library(SentimentAnalysis)
library(RColorBrewer)
library(wordcloud)
#library(sentiment)
#library(foo)
library(tidyverse)
library(tidytext)
library(e1071)
library(caret)
library(syuzhet)
library(gmodels)
library(plyr)
library(plotly)
library(DT)
library(sass)
data1 <-  Corpus(VectorSource(data))
removeLink <- function(d) gsub("http[^[:space;]]*","",d)
dataClean <- tm_map(data1, removeLink)
View(data1)
data1 <-  Corpus(VectorSource(data))
removeLink <- function(d) gsub("http[^[:space]]*","",d)
dataClean <- tm_map(data1, removeLink)
data <- rbind(dataVaksinCovid, dataVaksin, dataVaksinBooster, dataBooster)
data <- data %>% select(full_text)
data1 <-  Corpus(VectorSource(data$full_text))
removeLink <- function(d) gsub("http[^[:space]]*","",d)
dataClean <- tm_map(data1, removeLink)
data1 <-  Corpus(VectorSource(data$full_text))
removeLink <- function(d) gsub("http[^[:space:]]*","",d)
dataClean <- tm_map(data1, removeLink)
removenl <- function(d) gsub("\n"," ",d)
dataClean <- tm_map(dataClean, removenl)
removeComma <- function(d) gsub(",","",d)
dataClean <- tm_map(dataClean, removeComma)
removeTitik2 <- function(d) gsub(":","",d)
dataClean <- tm_map(dataClean, removTitik2)
data1 <-  Corpus(VectorSource(data$full_text))
removeLink <- function(d) gsub("http[^[:space:]]*","",d)
dataClean <- tm_map(data1, removeLink)
removenl <- function(d) gsub("\n"," ",d)
dataClean <- tm_map(dataClean, removenl)
removeComma <- function(d) gsub(",","",d)
dataClean <- tm_map(dataClean, removeComma)
removeTitik2 <- function(d) gsub(":","",d)
dataClean <- tm_map(dataClean, removeTitik2)
removeTitikKoma <- function(d) gsub(";","",d)
dataClean <- tm_map(dataClean, removeTitikKoma)
removeAmp <- function(d) gsub("&amp","",d)
dataClean <- tm_map(dataClean, removeAmp)
removeun <- function(d) gsub("@\\w+","",d)
dataClean <- tm_map(dataClean, removeun)
remove.all <- function(d) gsub("[^[:alpha:][:space:]]","",d)
dataClean <- tm_map(dataClean, remove.all)
dataClean <- tm_map(dataClean, removePunctuation)
dataClean <- tm_map(dataClean, tolower)
df <- data.frame(text=unlist(sapply(dataClean,'[')),stringAsFactors=F)
View(df)
View(df)
data1 <-  Corpus(VectorSource(data$full_text))
removeLink <- function(d) gsub("http[^[:space:]]*","",d)
dataClean <- tm_map(data1, removeLink)
removenl <- function(d) gsub("\n"," ",d)
dataClean <- tm_map(dataClean, removenl)
removeComma <- function(d) gsub(",","",d)
dataClean <- tm_map(dataClean, removeComma)
removeTitik2 <- function(d) gsub(":","",d)
dataClean <- tm_map(dataClean, removeTitik2)
removeTitikKoma <- function(d) gsub(";","",d)
dataClean <- tm_map(dataClean, removeTitikKoma)
removeAmp <- function(d) gsub("&amp","",d)
dataClean <- tm_map(dataClean, removeAmp)
removeun <- function(d) gsub("@\\w+","",d)
dataClean <- tm_map(dataClean, removeun)
remove.all <- function(d) gsub("[^[:alpha:][:space:]]","",d)
dataClean <- tm_map(dataClean, remove.all)
dataClean <- tm_map(dataClean, removePunctuation)
dataClean <- tm_map(dataClean, tolower)
df <- data.frame(text=unlist(sapply(dataClean,'[')),stringAsFactors=F)
write.csv(df,file="dataTwitterClean.csv")
dataChar <- as.character(df$text)
sentiment <- get_nrc_sentiment(dataChar)
mergeData <- cbind(df$text,sentiment)
par(mar=rep(3,4))
View(mergeData)
install.packages("RTextTools")
